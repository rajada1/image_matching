#!/usr/bin/env python3
"""
Script para testar as melhorias de precisÃ£o no sistema hÃ­brido Annoy + ORB
"""

import cv2
import numpy as np
import time
import os
from main import ImageMatcher

def test_precision_improvements():
    """Testa as melhorias de precisÃ£o implementadas"""
    print("ğŸ§ª TESTE DE MELHORIAS DE PRECISÃƒO")
    print("=" * 50)
    
    # Cria matcher com configuraÃ§Ãµes otimizadas
    matcher = ImageMatcher()
    
    print("ğŸ“Š ConfiguraÃ§Ãµes atuais:")
    print(f"   ORB features: {matcher.orb.getMaxFeatures()}")
    print(f"   Annoy trees: {matcher.annoy_n_trees}")
    print(f"   Annoy search_k: {matcher.annoy_search_k}")
    print(f"   Early stop threshold: {matcher.early_stop_threshold}")
    print(f"   Min threshold: {matcher.min_threshold}")
    print(f"   Hybrid threshold: {matcher.hybrid_threshold}")
    print(f"   Total imagens no banco: {len(matcher.database_features)}")
    
    if len(matcher.database_features) == 0:
        print("âš ï¸  Nenhuma imagem no banco! Execute primeiro o processamento.")
        return False
    
    # Verifica se hÃ¡ imagens de teste
    test_images = []
    for root, dirs, files in os.walk("."):
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg', '.png')) and 'train' in root.lower():
                test_images.append(os.path.join(root, file))
    
    if not test_images:
        print("âš ï¸  Nenhuma imagem de teste encontrada na pasta train_image/")
        print("ğŸ’¡ Coloque algumas imagens na pasta train_image/ para testar")
        return False
    
    print(f"\nğŸ” Testando com {len(test_images)} imagens de teste")
    
    total_tests = 0
    successful_tests = 0
    total_search_time = 0
    
    for test_image_path in test_images[:5]:  # Testa apenas as primeiras 5
        try:
            print(f"\nğŸ“¸ Testando: {os.path.basename(test_image_path)}")
            
            # Carrega imagem de teste
            query_image = cv2.imread(test_image_path)
            if query_image is None:
                print(f"   âŒ Erro ao carregar imagem")
                continue
            
            # Executa busca
            start_time = time.time()
            results = matcher.search_similar_images(query_image, top_k=5)
            search_time = time.time() - start_time
            
            total_search_time += search_time
            total_tests += 1
            
            if results:
                successful_tests += 1
                best_result = results[0]
                
                print(f"   âœ… Melhor match: {best_result['image_path']}")
                print(f"   ğŸ“Š Score: {best_result['similarity_score']:.4f}")
                print(f"   â±ï¸  Tempo: {search_time:.3f}s")
                print(f"   ğŸ” MÃ©todo: {best_result.get('search_method', 'unknown')}")
                
                # Detalhes do match hÃ­brido
                if 'match_details' in best_result:
                    details = best_result['match_details']
                    if 'orb_similarity' in details:
                        print(f"   ğŸ¯ ORB score: {details['orb_similarity']:.4f}")
                        print(f"   ğŸš€ Annoy score: {details['annoy_similarity']:.4f}")
                        print(f"   ğŸ”€ HÃ­brido: {details['hybrid_score']:.4f}")
                
                # Mostra todos os resultados
                print(f"   ğŸ“‹ Top {len(results)} resultados:")
                for i, result in enumerate(results):
                    print(f"      {i+1}. {result['image_path']} (score: {result['similarity_score']:.4f})")
            else:
                print(f"   âŒ Nenhum resultado encontrado")
                
        except Exception as e:
            print(f"   âŒ Erro no teste: {e}")
    
    # EstatÃ­sticas finais
    print(f"\nğŸ“Š ESTATÃSTICAS FINAIS:")
    print(f"   Total de testes: {total_tests}")
    print(f"   Testes bem-sucedidos: {successful_tests}")
    print(f"   Taxa de sucesso: {(successful_tests/total_tests*100):.1f}%")
    print(f"   Tempo mÃ©dio por busca: {(total_search_time/total_tests):.3f}s")
    
    if matcher.annoy_index is not None:
        print(f"   ğŸ“ˆ Ãndice Annoy ativo: {len(matcher.annoy_id_to_image):,} descritores")
    else:
        print(f"   âš ï¸  Ãndice Annoy nÃ£o carregado")
    
    success_rate = (successful_tests / total_tests) if total_tests > 0 else 0
    
    print(f"\nğŸ¯ AVALIAÃ‡ÃƒO DE PRECISÃƒO:")
    if success_rate >= 0.8:
        print(f"   ğŸŸ¢ EXCELENTE: Taxa de sucesso {success_rate:.1%}")
    elif success_rate >= 0.6:
        print(f"   ğŸŸ¡ BOM: Taxa de sucesso {success_rate:.1%}")
    elif success_rate >= 0.4:
        print(f"   ğŸŸ  MODERADO: Taxa de sucesso {success_rate:.1%}")
    else:
        print(f"   ğŸ”´ BAIXO: Taxa de sucesso {success_rate:.1%}")
    
    return success_rate >= 0.6

def test_different_thresholds():
    """Testa diferentes configuraÃ§Ãµes de threshold"""
    print("\nğŸ”§ TESTE DE CONFIGURAÃ‡Ã•ES DE THRESHOLD")
    print("=" * 40)
    
    matcher = ImageMatcher()
    
    # ConfiguraÃ§Ãµes para testar
    test_configs = [
        {"name": "Restritivo", "min_threshold": 0.7, "hybrid_threshold": 0.8},
        {"name": "Balanceado", "min_threshold": 0.5, "hybrid_threshold": 0.6},
        {"name": "Permissivo", "min_threshold": 0.3, "hybrid_threshold": 0.4},
        {"name": "Muito Permissivo", "min_threshold": 0.1, "hybrid_threshold": 0.2},
    ]
    
    # Pega uma imagem de teste
    test_image_path = None
    for root, dirs, files in os.walk("."):
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg')) and 'train' in root.lower():
                test_image_path = os.path.join(root, file)
                break
        if test_image_path:
            break
    
    if not test_image_path:
        print("âš ï¸  Nenhuma imagem de teste encontrada")
        return
    
    query_image = cv2.imread(test_image_path)
    if query_image is None:
        print("âŒ Erro ao carregar imagem de teste")
        return
    
    print(f"ğŸ–¼ï¸  Usando imagem: {os.path.basename(test_image_path)}")
    
    for config in test_configs:
        print(f"\nğŸ§ª Testando configuraÃ§Ã£o: {config['name']}")
        print(f"   Min threshold: {config['min_threshold']}")
        print(f"   Hybrid threshold: {config['hybrid_threshold']}")
        
        # Aplica configuraÃ§Ã£o
        original_min = matcher.min_threshold
        original_hybrid = matcher.hybrid_threshold
        
        matcher.min_threshold = config['min_threshold']
        matcher.hybrid_threshold = config['hybrid_threshold']
        
        try:
            start_time = time.time()
            results = matcher.search_similar_images(query_image, top_k=3)
            search_time = time.time() - start_time
            
            print(f"   â±ï¸  Tempo: {search_time:.3f}s")
            print(f"   ğŸ“Š Resultados: {len(results)}")
            
            if results:
                best_score = results[0]['similarity_score']
                avg_score = sum(r['similarity_score'] for r in results) / len(results)
                print(f"   ğŸ† Melhor score: {best_score:.4f}")
                print(f"   ğŸ“ˆ Score mÃ©dio: {avg_score:.4f}")
                
                for i, result in enumerate(results):
                    print(f"      {i+1}. {result['image_path']} ({result['similarity_score']:.4f})")
            else:
                print(f"   âŒ Nenhum resultado")
                
        except Exception as e:
            print(f"   âŒ Erro: {e}")
        finally:
            # Restaura configuraÃ§Ãµes originais
            matcher.min_threshold = original_min
            matcher.hybrid_threshold = original_hybrid

if __name__ == "__main__":
    print("ğŸ§ª TESTE DE MELHORIAS DE PRECISÃƒO")
    print("ğŸ¯ Validando algoritmo hÃ­brido Annoy + ORB")
    print("=" * 60)
    
    try:
        # Teste principal de precisÃ£o
        success = test_precision_improvements()
        
        if success:
            print("\nâœ… MELHORIAS DE PRECISÃƒO VALIDADAS!")
            print("ğŸ‰ O sistema hÃ­brido estÃ¡ funcionando corretamente")
            
            # Teste de diferentes thresholds
            test_different_thresholds()
            
        else:
            print("\nâš ï¸  ATENÃ‡ÃƒO: Baixa taxa de sucesso detectada")
            print("ğŸ’¡ Considere ajustar os thresholds ou verificar as imagens de teste")
            
    except Exception as e:
        print(f"\nâŒ ERRO NO TESTE: {e}")
        print("ğŸ”§ Verifique se o sistema estÃ¡ funcionando corretamente")
    
    print("\nğŸ“š PRÃ“XIMOS PASSOS:")
    print("1. Se a precisÃ£o estiver baixa, ajuste os thresholds via API:")
    print("   POST /performance/config")
    print("2. Use imagens de teste variadas para validar melhor")
    print("3. Monitore os logs durante as buscas para debugging")
    print("4. Execute 'python main.py' para acessar a API completa")